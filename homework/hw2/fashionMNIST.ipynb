{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Machine Learning - HW2\n",
    "Adam Ilyas 1002010\n",
    "\n",
    "## Convolutional Neural Network (CNN)\n",
    "\n",
    "We will use PyTorch to train a Convolutional Neural Network (CNN) to improve classification\n",
    "accuracy on the Fashion MNIST dataset. This dataset comprises 50,000 training examples and\n",
    "10,000 test examples of 28x28-pixel monochrome images of various clothing items. Let us begin by\n",
    "importing the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 10 classes enumerated in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0: 'T-shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress', \n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Angle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# data\n",
    "data_path = './data'\n",
    "if not os.path.isdir(data_path):\n",
    "    os.mkdir(data_path)\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(data_path, train=True, \n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.FashionMNIST(data_path, train=False, \n",
    "                                      download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None\n",
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True);\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12));\n",
    "columns = 7;\n",
    "rows = 7;\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    \n",
    "    img_no = numpy.random.randint(len(train_dataset))\n",
    "    img = train_dataset[img_no][0][0]\n",
    "    img_class = train_dataset[img_no][1].item()\n",
    "    label = labels[img_class]\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        #initialize the layers \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, \n",
    "                out_channels=16, \n",
    "                kernel_size=3, \n",
    "                stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=3, \n",
    "                stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # invoke the layers\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,train_loader,optimizer,epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data,target = data.to(device),target.to(device)\n",
    "            \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "        \n",
    "        # Foward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs,target)\n",
    "        \n",
    "        #Optimizer's step() function is used to update the weights after \n",
    "        # backpropogating the gradients\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch:',epoch,',loss:',loss.item())\n",
    "                     \n",
    "# Define test function\n",
    "# defind the variable \"pred\" which predicts the output and update the variable \"correct\" \n",
    "# to keep track of the no. of correctly classified objects to compute the accuracy of the CNN            \n",
    "def test(model,device,test_loader, plot=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    exampleSet = False\n",
    "    example_data = numpy.zeros([10,28,28])\n",
    "    example_pred = numpy.zeros(10)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data,target = data.to(device), target.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            _, pred = torch.max(outputs.data,1)\n",
    "            correct += (pred == target).sum()\n",
    "            \n",
    "            if not exampleSet:\n",
    "                for i in range(10):\n",
    "                    example_data[i] = data[i][0].to('cpu').numpy()\n",
    "                    example_pred[i] = pred[i].to('cpu').numpy()\n",
    "                exampleSet = True\n",
    "    \n",
    "    set_accuracy = (100*correct/len(test_loader.dataset)).item()\n",
    "    print(f'Test set accuracy: {set_accuracy}%')\n",
    "    \n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(12,6));\n",
    "        for i in range(10):\n",
    "            plt.subplot(2,5,i+1)\n",
    "            plt.imshow(example_data[i],cmap='gray',interpolation='none')\n",
    "            plt.title(labels[example_pred[i]])\n",
    "            plt.axis('off')\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LRATE = 0.001\n",
    "\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LRATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier initialization\n",
    "Initizialize weights using\n",
    "$$w^{(l)} \\sim \\mathcal{N}\\left(0, \\sqrt{\\frac{2}{n^{(l)}+n^{(l-1)}}}\\right)$$\n",
    "where $n^{(l)}$ is the number of neurons in layer $l$.\n",
    "\n",
    "This makes the variance of the activations in each layer similar to\n",
    "one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization function, first checks the module type,\n",
    "# then applies the desired changes to the weights\n",
    "def xavier_init_to_linear(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.uniform_(m.weight)\n",
    "        \n",
    "model.apply(xavier_init_to_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,NUM_EPOCHS + 1):\n",
    "    test(model,device,test_loader)\n",
    "    train(model,device,train_loader,optimizer,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
