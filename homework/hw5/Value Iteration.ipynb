{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical and Machine Learning (01.113) - HW5 Question 3\n",
    "## Problem 4: Robot vs Snakes\n",
    "In this problem, we will simulate a robot navigating a room trying to find the exit. \n",
    "\n",
    "The robot is bleeding and loses 1 hitpoint for every step it takes before it finds the exit. \n",
    "\n",
    "To make matters worse, there are 2 snakes in the centre of the room. If the robot steps onto a square with a snake, the snake will bite it and cause it to lose 15 hitpoints! \n",
    "\n",
    "As the robot is terrified of being bitten, it is very nervous and does not strictly respond to commands; \n",
    "- if told to move in a certain direction, it will only do so half the time. \n",
    "- One quarter of the time it will instead move to the left of the commanded direction, and\n",
    "- another quarter of the time it will move to the right of the commanded direction.\n",
    "\n",
    "Can you help train the robot to find its way out? Begin by installing OpenAI’s gym module (`pip install gym`), and include the following code in your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from gym.envs.toy_text import discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "\n",
    "GOAL = 4 # upper right corner\n",
    "START = 20 # lower left corner\n",
    "SNAKE1 = 7\n",
    "SNAKE2 = 17\n",
    "\n",
    "eps = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot_vs_snakes_world(discrete.DiscreteEnv):\n",
    "    def __init__(self):\n",
    "        self.shape = [5, 5]\n",
    "        \n",
    "        nS = np.prod(self.shape) # total states\n",
    "        nA = 4 # total actions\n",
    "        \n",
    "        MAX_X, MAX_Y = self.shape\n",
    "        \n",
    "        P = {}\n",
    "        grid = np.arange(nS).reshape(self.shape)\n",
    "        \"\"\"\n",
    "        grid:  \n",
    "               [ 0,  1,  2,  3,  4],\n",
    "               [ 5,  6,  7,  8,  9],\n",
    "               [10, 11, 12, 13, 14],\n",
    "               [15, 16, 17, 18, 19],\n",
    "               [20, 21, 22, 23, 24]\n",
    "        \"\"\"\n",
    "        it = np.nditer(grid, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            s = it.iterindex\n",
    "            y, x = it.multi_index\n",
    "            \n",
    "            P[s] = {a: [] for a in range(nA)}\n",
    "            \"\"\"{0: [], 1: [], 2: [], 3: []}\"\"\"\n",
    "            is_done = lambda s: s == GOAL # location\n",
    "            \n",
    "            if is_done(s):\n",
    "                reward = 0. # OK.\n",
    "            elif s in [SNAKE1, SNAKE2]:\n",
    "                reward = -15. # OUCH\n",
    "            else:\n",
    "                reward = -1. # BLEEDING\n",
    "                \n",
    "            if is_done(s):\n",
    "                P[s][UP]=[(1.0,s,reward,True)]\n",
    "                P[s][RIGHT]=[(1.0,s,reward,True)]\n",
    "                P[s][DOWN]=[(1.0,s,reward,True)]\n",
    "                P[s][LEFT]=[(1.0,s,reward,True)]\n",
    "            else:\n",
    "                # where to move (0 if cant move, else move) \n",
    "                # (since s in [0, 1 .., 24]\n",
    "                ns_up = s if y==0 else s-MAX_X\n",
    "                ns_right = s if x==(MAX_X-1) else s+1\n",
    "                ns_down = s if y==(MAX_Y-1) else s+MAX_X\n",
    "                ns_left = s if x==0 else s-1\n",
    "                \n",
    "                # prob, next state , reward, boolean finish\n",
    "                # reward in [0, -15, -1]\n",
    "                P[s][UP] = [(1-(2*eps),ns_up,reward,is_done(ns_up)),\n",
    "                            (eps,ns_right,reward,is_done(ns_right)),\n",
    "                            (eps,ns_left,reward,is_done(ns_left))]\n",
    "                \n",
    "                P[s][RIGHT]=[(1-(2*eps),ns_right,reward,is_done(ns_right)),  \n",
    "                             (eps,ns_up,reward,is_done(ns_up)),\n",
    "                             (eps,ns_down,reward,is_done(ns_down))]\n",
    "                \n",
    "                P[s][DOWN] = [(1-(2*eps),ns_down,reward,is_done(ns_down)),\n",
    "                              (eps,ns_right,reward,is_done(ns_right)),\n",
    "                              (eps,ns_left,reward,is_done(ns_left))]\n",
    "                \n",
    "                P[s][LEFT] = [(1-(2*eps) , ns_left , reward , is_done(ns_left)) ,\n",
    "                              ( eps , ns_up , reward , is_done(ns_up)) ,\n",
    "                              ( eps , ns_down , reward , is_done(ns_down))]\n",
    "                \n",
    "            it.iternext()\n",
    "            \n",
    "        isd = np.zeros(nS)\n",
    "        isd[START] = 1.\n",
    "        self.P = P # {}\n",
    "        \n",
    "        super(Robot_vs_snakes_world, self).__init__(nS , nA , P , isd)\n",
    "                \n",
    "    def _render(self):\n",
    "        grid = np.arange(self.nS).reshape(self.shape)\n",
    "        it = np.nditer(grid, flags=['multi_index'])\n",
    "\n",
    "        while not it.finished:\n",
    "            s = it.iterindex\n",
    "            y, x = it.multi_index\n",
    "            \n",
    "            if self.s == s:\n",
    "                output = u\" \\u001b[30mR \"\n",
    "            elif s == GOAL:\n",
    "                output = u\" \\u001b[32mG \"\n",
    "            elif s in [SNAKE1, SNAKE2]:\n",
    "                output =  u\" \\u001b[31mS \"\n",
    "#                 output = \" S \"\n",
    "            else:\n",
    "                output = u\" \\u001b[37mo \"\n",
    "                \n",
    "            if x == 0:\n",
    "                output = output.lstrip()\n",
    "            if x == self.shape[1] - 1:\n",
    "                output = output.rstrip()\n",
    "                \n",
    "            sys.stdout.write(output)\n",
    "            \n",
    "            if x == self.shape[1] - 1:\n",
    "                sys.stdout.write(\"\\n\")\n",
    "                \n",
    "            it.iternext()\n",
    "            \n",
    "        sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write\n",
    "`env = Robot_vs_snakes_world()`\n",
    "to start the environment, which is a 5 x 5 grid. \n",
    "\n",
    "Locations on the grid are numbered starting from 0\n",
    "on the upper-left, and increasing in a row-wise manner; i.e. the upper-right is numbered 4 (exit/goal\n",
    "state), the lower-left (starting location of robot) is numbered 20, the lower-right corner is numbered\n",
    "24, and so on. You can access the robot’s location at any time using `env.s` and issue a command to move using `env.step(DIR)`\n",
    "where `DIR` is `UP` , `DOWN` , `LEFT` or `RIGHT`. \n",
    "\n",
    "Finally, `env.p[state][action]` returns a list of tuples each corresponding to a possible next state $j$ and of the form \n",
    "- (probability of transitioning to state $j$, $j$, reward, goal state?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[30mR  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = Robot_vs_snakes_world()\n",
    "env._render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [(0.5, 0, -1.0, False), (0.25, 1, -1.0, False), (0.25, 0, -1.0, False)], 1: [(0.5, 1, -1.0, False), (0.25, 0, -1.0, False), (0.25, 5, -1.0, False)], 2: [(0.5, 5, -1.0, False), (0.25, 1, -1.0, False), (0.25, 0, -1.0, False)], 3: [(0.5, 0, -1.0, False), (0.25, 0, -1.0, False), (0.25, 5, -1.0, False)]}\n"
     ]
    }
   ],
   "source": [
    "# env.P[current state][direction to move]\n",
    "# probability, next state, next state reward , goal state\n",
    "print(env.P[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value iteration, for estimating $\\pi \\approx \\pi_{*}$\n",
    "Algorithm parameter: \n",
    "- a small threshold $\\theta>0$ determining accuracy of estimation\n",
    "- **Initialize** $V(s),$ for all $s \\in \\mathcal{S}^{+},$ arbitrarily except that $V($terminal$)=0$\n",
    "\n",
    "\n",
    "Loop until $\\Delta<$ some threshold $\\theta$ \n",
    "- $\\Delta \\leftarrow 0$\n",
    "- Loop for each $s \\in S$:\n",
    "- - $v \\leftarrow V(s)$\n",
    "- - $V(s) \\leftarrow \\max _{a} \\sum_{s^{\\prime}, r} p\\left(s^{\\prime}, r | s, a\\right)\\left[r+\\gamma V\\left(s^{\\prime}\\right)\\right]$\n",
    "- - $\\Delta \\leftarrow \\max (\\Delta,|v-V(s)|)$\n",
    "\n",
    "Output a deterministic policy $\\pi \\approx \\pi_{*}$ such that\n",
    "- $\\pi(s)=\\arg \\max _{a} \\sum_{s^{\\prime}, r} p\\left(s^{\\prime}, r | s, a\\right)\\left[r+\\gamma V\\left(s^{\\prime}\\right)\\right]$\n",
    "\n",
    "\n",
    "Greedy policy with respect to optimal value function:\n",
    "$$\\pi(s) \\approx \\underset{a}{\\arg \\max } \\sum_{s^{\\prime}, r} p\\left(s^{\\prime}, r | s, a\\right)\\left[r+\\gamma v_{*}\\left(s^{\\prime}\\right)\\right] = \\underset{a}{\\arg \\max } q_{*}(s, a)=\\pi_{*}(s)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.0000001 # small algorithm parameter\n",
    "discount_factor = 1.\n",
    "\n",
    "iter_state = range(env.nS)\n",
    "iter_action = range(env.nA)\n",
    "\n",
    "def bellman_equation(state, V):\n",
    "    state_values = []\n",
    "    for action in iter_action:\n",
    "        next_info = env.P[state][action]\n",
    "        components = []\n",
    "        for next_prob, next_state, reward, _ in next_info:\n",
    "            components.append(next_prob * (reward + discount_factor * V[next_state]))\n",
    "        state_values.append(sum(components))\n",
    "    return max(state_values)\n",
    "\n",
    "def deterministic_policy(V, policy):\n",
    "    for state in iter_state:\n",
    "        state_values = []\n",
    "        for action in iter_action:\n",
    "            next_info = env.P[state][action]\n",
    "            components = []\n",
    "            for next_prob, next_state, reward, _ in next_info:\n",
    "                components.append(next_prob * (reward + discount_factor * V[next_state]))\n",
    "            state_values.append(sum(components))\n",
    "        a = np.argmax(state_values)\n",
    "        policy[state, a] = 1\n",
    "    return policy\n",
    "\n",
    "def value_iteration(env):\n",
    "    # initialise V(s) for all s\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for state in iter_state:\n",
    "            v_prev = V[state]\n",
    "            V[state] = bellman_equation(state, V)\n",
    "            #update delta\n",
    "            delta = max(delta, np.abs(v_prev - V[state]))\n",
    "        if delta<theta:\n",
    "            break\n",
    "            \n",
    "    # Create a deterministic policy using the optimal value function\n",
    "    policy = np.zeros([env.nS, env.nA])\n",
    "    policy = deterministic_policy(V, policy)\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[30mR  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[30mR  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[30mR  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[30mR  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[30mR  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[30mR  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[30mR  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[30mR  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[30mR  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[30mR  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[30mR  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[30mR  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[32mG\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[30mR\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[31mS  \u001b[37mo  \u001b[37mo\n",
      "\u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo  \u001b[37mo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = Robot_vs_snakes_world()\n",
    "policy, V = value_iteration(env)\n",
    "\n",
    "env._render()\n",
    "while env.s != GOAL:\n",
    "    DIR = np.argmax(policy[env.s])\n",
    "    env.step(DIR)\n",
    "    env._render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Actions\n",
      "\u001b[30mR  \u001b[30mR  \u001b[30mU  \u001b[30mR  \u001b[30mU\n",
      "\u001b[30mU  \u001b[30mU  \u001b[31mR  \u001b[30mR  \u001b[30mU\n",
      "\u001b[30mU  \u001b[30mU  \u001b[30mR  \u001b[30mR  \u001b[30mU\n",
      "\u001b[30mU  \u001b[30mL  \u001b[31mR  \u001b[30mR  \u001b[30mU\n",
      "\u001b[30mR  \u001b[30mR  \u001b[30mD  \u001b[30mR  \u001b[30mU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_map = {0: \"U\", 1:\"R\", 2:\"D\", 3:\"L\"}\n",
    "\n",
    "def analyse_policy(policy):\n",
    "    grid = np.arange(env.nS).reshape(env.shape)\n",
    "    it = np.nditer(grid, flags=['multi_index'])\n",
    "\n",
    "    while not it.finished:\n",
    "        s = it.iterindex\n",
    "        y, x = it.multi_index\n",
    "\n",
    "        if s in [SNAKE1, SNAKE2]:\n",
    "            best_dir = np.argmax(policy[s])\n",
    "            output = u\" \\u001b[31m\" + f\"{dir_map[best_dir] } \"\n",
    "        else:\n",
    "            best_dir = np.argmax(policy[s])\n",
    "            output = u\" \\u001b[30m\" + f\"{dir_map[best_dir] } \"\n",
    "\n",
    "        if x == 0:\n",
    "            output = output.lstrip()\n",
    "        if x == env.shape[1] - 1:\n",
    "            output = output.rstrip()\n",
    "        sys.stdout.write(output)\n",
    "        if x == env.shape[1] - 1:\n",
    "            sys.stdout.write(\"\\n\")\n",
    "        it.iternext()\n",
    "\n",
    "    sys.stdout.write(\"\\n\")\n",
    "\n",
    "print(\"Best Actions\")\n",
    "analyse_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Does the robot try to avoid the snakes? If so, refer to the policy function obtained in (a) to explain in what way it does so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Policy')\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values\n",
      "[-18.6392237  -15.69855024 -11.40619278  -3.11383538   0.\n",
      " -20.52057086 -20.28326531 -25.21538992  -5.34150613  -3.11383538\n",
      " -22.13667743 -21.36889067 -18.77235465  -8.02451839  -6.08406305\n",
      " -24.06722348 -23.92831575 -29.8249919  -10.58844133  -8.91885581\n",
      " -24.16235804 -22.20992543 -19.35073033 -12.49153532 -11.44308231]\n"
     ]
    }
   ],
   "source": [
    "print(\"Action values\")\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_reward(s):\n",
    "    if s==GOAL:\n",
    "        reward = 0. # OK.\n",
    "    elif s in [SNAKE1, SNAKE2]:\n",
    "        reward = -15. # OUCH\n",
    "    else:\n",
    "        reward = -1. # BLEEDING\n",
    "    return reward\n",
    "\n",
    "def simulate(n_run=100):\n",
    "    snakes = []\n",
    "    rewards = []\n",
    "    steps = []\n",
    "    for _ in range(n_run):\n",
    "        snake_count = 0\n",
    "        reward_count = 0\n",
    "        step_count = 0\n",
    "        env = Robot_vs_snakes_world()\n",
    "        policy, V = value_iteration(env)\n",
    "\n",
    "        while env.s != GOAL:\n",
    "            step_count += 1\n",
    "            reward_count+=step_reward(env.s)\n",
    "            if env.s in [SNAKE1, SNAKE2]:\n",
    "                snake_count +=1\n",
    "            DIR = np.argmax(policy[env.s])\n",
    "            env.step(DIR)\n",
    "            \n",
    "        snakes.append(snake_count)\n",
    "        rewards.append(reward_count)\n",
    "        steps.append(step_count)\n",
    "    return snakes, rewards, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. times meeting Snake: 0.26\n",
      "Avg. Rewards obtained: -25.37\n",
      "Avg. Steps taken: 21.73\n"
     ]
    }
   ],
   "source": [
    "snakes, rewards, steps = simulate()\n",
    "# in 100 runs\n",
    "print(f\"Avg. times meeting Snake: {np.mean(snakes)}\")\n",
    "print(f\"Avg. Rewards obtained: {np.mean(rewards)}\")\n",
    "print(f\"Avg. Steps taken: {np.mean(steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. times meeting Snake: 0.283\n",
      "Avg. Rewards obtained: -24.44\n",
      "Avg. Steps taken: 20.478\n"
     ]
    }
   ],
   "source": [
    "snakes, rewards, steps = simulate(1000)\n",
    "# in 1000 runs\n",
    "print(f\"Avg. times meeting Snake: {np.mean(snakes)}\")\n",
    "print(f\"Avg. Rewards obtained: {np.mean(rewards)}\")\n",
    "print(f\"Avg. Steps taken: {np.mean(steps)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
